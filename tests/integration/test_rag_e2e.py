"""
End-to-End RAG Integration Tests

è¿™äº›æµ‹è¯•éœ€è¦çœŸå®çš„æœåŠ¡ç¯å¢ƒï¼š
- Redisï¼ˆè¿è¡Œä¸­ï¼‰
- MinIOï¼ˆè¿è¡Œä¸­ï¼‰
- ChromaDBï¼ˆå·²åˆå§‹åŒ–ï¼‰
- OpenAI APIï¼ˆå¯ç”¨ï¼‰

è¿è¡Œå‰å‡†å¤‡ï¼š
1. ç¡®ä¿ Redis è¿è¡Œï¼šdocker-compose up -d redis
2. ç¡®ä¿ MinIO è¿è¡Œï¼šdocker-compose up -d minio
3. åˆå§‹åŒ–çŸ¥è¯†åº“ï¼šuv run python scripts/ingest_knowledge.py --path data/knowledge/
4. é…ç½® .env æ–‡ä»¶ä¸­çš„ OPENAI_API_KEY

è¿è¡Œæµ‹è¯•ï¼š
    uv run pytest tests/integration/test_rag_e2e.py -v -s
"""

from pathlib import Path

import os
import pytest
import time

from app.services.rag_service import get_rag_service, reset_rag_service
from app.services.taxonomy_service import get_taxonomy_service
from app.worker.diagnosis_tasks import analyze_image


@pytest.fixture(scope="module")
def verify_environment():
    """éªŒè¯æµ‹è¯•ç¯å¢ƒæ˜¯å¦å°±ç»ª"""
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    required_env_vars = ["OPENAI_API_KEY"]
    missing_vars = [var for var in required_env_vars if not os.getenv(var)]

    if missing_vars:
        pytest.skip(f"Missing required environment variables: {', '.join(missing_vars)}")

    # æ£€æŸ¥ ChromaDB æ˜¯å¦å·²åˆå§‹åŒ–
    chroma_path = os.getenv("CHROMA_PERSIST_DIRECTORY", "data/chroma")
    if not os.path.exists(chroma_path):
        pytest.skip(
            f"ChromaDB not initialized at {chroma_path}. "
            "Run: uv run python scripts/ingest_knowledge.py --path data/knowledge/"
        )

    # æ£€æŸ¥çŸ¥è¯†æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    knowledge_dir = Path("data/knowledge")
    if not knowledge_dir.exists():
        pytest.skip(f"Knowledge directory not found: {knowledge_dir}")

    yield True

    # æ¸…ç†ï¼šé‡ç½® RAG service singleton
    reset_rag_service()


@pytest.fixture(scope="module")
def test_image_url(verify_environment):
    """
    åˆ›å»ºæˆ–ä½¿ç”¨æµ‹è¯•å›¾ç‰‡çš„ URLã€‚

    æ³¨æ„ï¼šçœŸå®ç¯å¢ƒéœ€è¦æœ‰ MinIO è¿è¡Œå¹¶å¯è®¿é—®ã€‚
    å¯¹äºæµ‹è¯•ç¯å¢ƒï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå¯å…¬å¼€è®¿é—®çš„ç¤ºä¾‹å›¾ç‰‡ URLã€‚
    """
    # ä½¿ç”¨ä¸€ä¸ªå…¬å¼€çš„ç•ªèŒ„ç—…å®³å›¾ç‰‡ç¤ºä¾‹
    # æ³¨æ„ï¼šè¿™åªæ˜¯ä¸€ä¸ªç¤ºä¾‹ URLï¼Œå®é™…æµ‹è¯•æ—¶åº”è¯¥ä½¿ç”¨çœŸå®ä¸Šä¼ çš„å›¾ç‰‡
    return (
        "https://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/"
        "Phytophthora_infestans_Tomato.jpg/640px-Phytophthora_infestans_Tomato.jpg"
    )


@pytest.mark.integration
@pytest.mark.slow
class TestEndToEndRAGDiagnosis:
    """ç«¯åˆ°ç«¯ RAG è¯Šæ–­æµ‹è¯•"""

    def test_rag_service_initialized(self, verify_environment):
        """æµ‹è¯• RAG æœåŠ¡å¯ä»¥æ­£ç¡®åˆå§‹åŒ–"""
        rag = get_rag_service()
        assert rag is not None

        # æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½
        docs = rag.query("ç•ªèŒ„æ™šç–«ç—…", top_k=3)
        assert isinstance(docs, list)
        # ChromaDB åº”è¯¥è¿”å›ä¸€äº›ç›¸å…³æ–‡æ¡£
        # å¦‚æœçŸ¥è¯†åº“ä¸ºç©ºï¼Œè¿”å›ç©ºåˆ—è¡¨ä¹Ÿæ˜¯æ­£å¸¸çš„
        print(f"âœ… RAG service initialized, retrieved {len(docs)} documents")

    def test_taxonomy_service_initialized(self, verify_environment):
        """æµ‹è¯• Taxonomy æœåŠ¡å¯ä»¥æ­£ç¡®åˆå§‹åŒ–"""
        taxonomy = get_taxonomy_service()
        assert taxonomy is not None

        # æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½
        entry = taxonomy.get_by_model_label("late_blight")
        assert entry is not None
        assert entry.action_policy == "RETRIEVE"
        print(f"âœ… Taxonomy service initialized, found entry: {entry.zh_scientific_name}")

    def test_end_to_end_diagnosis_with_report(self, verify_environment, test_image_url):
        """
        å®Œæ•´çš„ç«¯åˆ°ç«¯è¯Šæ–­æµç¨‹æµ‹è¯•ã€‚

        æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªçœŸå®æµ‹è¯•ï¼Œä¼šï¼š
        1. è°ƒç”¨ Celery ä»»åŠ¡
        2. æŸ¥è¯¢ ChromaDB
        3. è°ƒç”¨ OpenAI API
        4. ç”Ÿæˆ LLM æŠ¥å‘Š

        æ­¤æµ‹è¯•ä¼šæ¶ˆè€— OpenAI API é…é¢ã€‚
        """
        print("\nğŸ” Starting end-to-end diagnosis test...")
        print(f"   Image URL: {test_image_url}")

        # æäº¤è¯Šæ–­ä»»åŠ¡
        task_result = analyze_image.apply_async(
            args=[test_image_url],
            kwargs={"crop_type": "ç•ªèŒ„"}
        )

        print(f"   Task ID: {task_result.id}")
        print(f"   Task status: {task_result.status}")

        # ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆæœ€å¤š 60 ç§’ï¼‰
        timeout = 60
        start_time = time.time()

        while not task_result.ready():
            if time.time() - start_time > timeout:
                pytest.fail(f"Task timeout after {timeout}s")

            print(f"   Waiting for task... (status: {task_result.status})")
            time.sleep(2)

        # è·å–ç»“æœ
        try:
            result = task_result.get(timeout=5)
        except Exception as e:
            pytest.fail(f"Task failed with exception: {str(e)}")

        print("\nâœ… Task completed successfully")
        print(f"   Model label: {result.get('model_label')}")
        print(f"   Diagnosis: {result.get('diagnosis_name')}")
        print(f"   Confidence: {result.get('confidence'):.2%}")
        print(f"   Action policy: {result.get('action_policy')}")

        # éªŒè¯åŸºæœ¬å­—æ®µ
        assert "model_label" in result
        assert "confidence" in result
        assert "diagnosis_name" in result
        assert "action_policy" in result

        # å¦‚æœæ˜¯ RETRIEVE ç­–ç•¥ï¼Œåº”è¯¥æœ‰æŠ¥å‘Š
        if result.get("action_policy") == "RETRIEVE":
            print("\nğŸ“Š LLM Report:")
            if result.get("report"):
                # æ‰“å°æŠ¥å‘Šçš„å‰ 200 ä¸ªå­—ç¬¦
                report_preview = (
                    result["report"][:200] + "..."
                    if len(result["report"]) > 200
                    else result["report"]
                )
                print(f"   {report_preview}")

                # éªŒè¯æŠ¥å‘ŠåŒ…å«é¢„æœŸçš„ç« èŠ‚
                report_lower = result["report"].lower()
                # æ ¹æ®æŠ¥å‘Šæ¨¡æ¿ï¼Œåº”è¯¥åŒ…å«è¿™äº›å†…å®¹
                assert any(keyword in report_lower for keyword in ["ç—…å®³", "é˜²æ²»", "é¢„é˜²", "ç•ªèŒ„"])
                print(f"   âœ… Report generated successfully ({len(result['report'])} chars)")
            else:
                print("   âš ï¸  No report generated")
                print(f"   Error: {result.get('report_error', 'Unknown error')}")

                # æŠ¥å‘Šç”Ÿæˆå¤±è´¥ä¸åº”è¯¥å¯¼è‡´ä»»åŠ¡å¤±è´¥
                assert "report_error" in result

        print("\nâœ… End-to-end test passed!")

    @pytest.mark.skipif(
        os.getenv("CI") == "true",
        reason="Skip in CI environment (requires external services)"
    )
    def test_rag_retrieval_quality(self, verify_environment):
        """æµ‹è¯• RAG æ£€ç´¢è´¨é‡"""
        rag = get_rag_service()

        # æµ‹è¯•å‡ ä¸ªå¸¸è§ç—…å®³çš„æ£€ç´¢
        test_queries = [
            ("ç•ªèŒ„æ™šç–«ç—…", "ç•ªèŒ„æ™šç–«ç—…ç”±è‡´ç—…ç–«éœ‰å¼•èµ·"),
            ("ç•ªèŒ„ç™½ç²‰ç—…", "ç™½ç²‰ç—…"),
            ("ç•ªèŒ„èšœè™«", "èšœè™«"),
        ]

        print("\nğŸ” Testing RAG retrieval quality...")

        for query, expected_keyword in test_queries:
            docs = rag.query(query, top_k=3)
            print(f"   Query: '{query}' â†’ {len(docs)} documents")

            # éªŒè¯è‡³å°‘æœ‰ä¸€ä¸ªæ–‡æ¡£åŒ…å«é¢„æœŸå…³é”®è¯
            if len(docs) > 0:
                found = any(expected_keyword in doc.page_content for doc in docs)
                if found:
                    print("      âœ… Found relevant document")
                else:
                    print(f"      âš ï¸  Expected keyword '{expected_keyword}' not found in results")
            else:
                print("      âš ï¸  No documents retrieved (knowledge base may be empty)")

        print("âœ… RAG retrieval quality test completed")


@pytest.mark.integration
class TestKnowledgeBaseIngestion:
    """çŸ¥è¯†åº“æ‘„å–æµ‹è¯•"""

    def test_knowledge_files_exist(self, verify_environment):
        """æµ‹è¯•çŸ¥è¯†æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        knowledge_dir = Path("data/knowledge")

        # æ£€æŸ¥ç¤ºä¾‹æ–‡ä»¶
        example_files = [
            "diseases/powdery_mildew.md",
            "diseases/late_blight.md",
            "crops/tomato.md",
        ]

        print("\nğŸ“ Checking knowledge files...")

        for file_path in example_files:
            full_path = knowledge_dir / file_path
            if full_path.exists():
                print(f"   âœ… {file_path} ({full_path.stat().st_size} bytes)")
            else:
                print(f"   âš ï¸  {file_path} not found")

        print("âœ… Knowledge files check completed")

    def test_chroma_db_persistence(self, verify_environment):
        """æµ‹è¯• ChromaDB æŒä¹…åŒ–"""
        chroma_path = os.getenv("CHROMA_PERSIST_DIRECTORY", "data/chroma")

        print("\nğŸ’¾ Checking ChromaDB persistence...")
        print(f"   Path: {chroma_path}")

        if os.path.exists(chroma_path):
            # æ£€æŸ¥ ChromaDB æ–‡ä»¶
            chroma_files = list(Path(chroma_path).rglob("*"))
            print(f"   âœ… ChromaDB directory exists ({len(chroma_files)} files)")

            # æ˜¾ç¤ºä¸€äº›æ–‡ä»¶
            for file in chroma_files[:5]:
                print(f"      - {file.relative_to(chroma_path)}")

            if len(chroma_files) > 5:
                print(f"      ... and {len(chroma_files) - 5} more files")
        else:
            print("   âš ï¸  ChromaDB directory not found")

        print("âœ… ChromaDB persistence check completed")


if __name__ == "__main__":
    # å¯ä»¥ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶è¿›è¡Œå¿«é€Ÿæµ‹è¯•
    pytest.main([__file__, "-v", "-s", "-m", "integration"])
